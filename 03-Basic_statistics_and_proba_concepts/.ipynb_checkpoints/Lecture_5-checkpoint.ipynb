{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Statistical Inference: Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "- II. [What is statistical inference ?](#II) \n",
    "    * II.1 [Point estimate](#II.1-Point-estimate:)\n",
    "    * II.2 [Confidence interval](#II.2-Confidence-interval:)\n",
    "    * II.3 [Hypothesis testing](#II.3-Hypothesis-testing) \n",
    "- III. [Maximum Likelihood (MLE)](#III)\n",
    "    - III.1 Likelihood function\n",
    "    - III.2 Likelihood approach  ; Show that analyticaly the likelihood yi\n",
    "    - III.3 MLE applied to homoscedastic errors\n",
    "    - III.4 Properties of MLE estimators\n",
    "    - III.5 MLE Confidence intervals\n",
    "    - III.6 MLE applied to heteroscedastic errors\n",
    "- IV. Goodness of fit and model selection\n",
    "    - IV.1 Goodness of fit for a model\n",
    "    - IV.2 Model Comparison\n",
    "    \n",
    "- X. [References and supplementary material](#X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. What is statistical inference ?  <a class=\"anchor\" id=\"II\"></a>\n",
    "\n",
    "Statistical inference is the process that consists in deriving information about a phenomenon/something based on a data set. More specifically, it the process of using data to infer the distribution that \"generated\" the data. This is what is called \"learning\" in the context of computer science. \n",
    "\n",
    "Statistical inference implies first to define a **statistical model** (or several) that describe(s) the data. This can be distribution function(s) but also a regression law(s), that is (are) parametrized by a finite number of parameters, generally denoted $\\theta$ in most of statistical books. Then, the remaining of the \"game\" is to confront this model to the data to see if it is well suited, and whether we can infer the values of its parameters.  \n",
    "\n",
    "There is basically three types of inference one draws from data:\n",
    "- ** Point estimation **: What is the best estimate for a model parameter $\\theta$ based on the available data ? \n",
    "- ** Confidence estimation **: How confident should we be about our point estimate ? \n",
    "- ** Hypothesis testing **: Are the data at hand consistent with a given hypothesis or model ? \n",
    "\n",
    "This is common to any statistical paradigm (i.e. Frequentist and Bayesian). We will see first how statistical inference is performed under the \"classical\" (aka frequentist) paradigm. In a future lecture, we will see the Bayesian approach and try to understand the \"philosphical\" differences between those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. 1 Point estimate:\n",
    "\n",
    "For frequentists, thist consists in deriving a single **best** guess for a quantity of interest, that can be a parameter in a parametric model, a regression function, a CDF $H(x)$, a pdf $h(x)$ or predictions for a future value $Y$ of a random variable. \n",
    "\n",
    "By convention, the point estimate of a parameter $\\theta$ is denoted $\\hat{\\theta}$. Remember that here, there is one *single fixed value* of $\\theta$, while the estimator $\\hat{\\theta}$ depends on the data, and is therefore a random variable.   \n",
    "\n",
    "A point estimator $\\hat{\\theta}$ of a parameter $\\theta$ is a function of the radom variables $X_1$, $X_2$, ... such that:    \n",
    "$$\n",
    "\\hat{\\theta} = g(X_1, X_2, X_3, ... X_n)\n",
    "$$\n",
    "\n",
    "As for any estimator you have encountered in descriptive statistics, this estimator can be biased (i.e. its value could differ from its true value by some amount), and be characterized by some variance (remember that $\\hat{\\theta}$ is a random variable). \n",
    "\n",
    "You could think that the \"(un)-biased\" character of an estimator is critical property of the estimator we would look at, but in fact this is not always critical, and many of the estimators we will consider are biased. More important is that a point estimator $\\hat{\\theta}$ **asymptotically converges** to the true parameter value. Mathetematicians then states that an estimator is **consistent**.  \n",
    "\n",
    "The distribution of $\\hat{\\theta}$ is called the **sampling distribution**.  \n",
    "\n",
    "**Note:**   \n",
    "For those who are familiar with bayesian statistics, the fact that $\\theta$ is not considered as a random variable, is one of the key difference between frequentist and bayesian inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 Confidence interval: \n",
    "\n",
    "For frequentists, a **confidence interval** for a parameter $\\theta$ is an interval $C_n = (a, b)$ where $a = a(X_1, X_2, ..., X_n)$ and $b = b(X_1, X_2, ..., X_n)$ are functions of the data such that:    \n",
    "$$\n",
    "p(\\theta \\in C_n) \\, \\leq \\, 1-\\alpha, ~{\\rm {for~all}~\\theta\\,\\in \\, \\Theta}\n",
    "$$\n",
    "\n",
    "Note that $\\Theta$ is the parameter space associated to $\\theta$ (i.e. all the values that could in principle be taken by $\\theta$). In general $\\alpha = 0.05$ is chosen, which defines a 95% confidence interval. \n",
    "\n",
    "An important point to keep in mind, in interpreting confidence intervals in *a frequentist way*, is that a confidence interval **is not a probability statement about $\\theta$** since $\\theta $ is a fixed quantity (i.e. $\\theta$ is NOT a random variable). A 95% confidence interval means that if you repeat your observation over and over, then, 95% of the time $\\theta$ will fall in your confidence interval. [Wasserman](#WAS04) suggests an alternative interpretation. Imagine that you measure one day one parameter $\\theta_1$ and derive a 95% confidence interval $C_1$. The next day, you do it for another parameter $\\theta_2$ (possibly associated to a different experiment), and get $C_2$. And so on. Imagine you did it for 100 parameters. Then, what, 95 times you will have trapped the true parameter value, and 5 times you won't. In other words, your confidence interval $C_n$ is a random variable.  \n",
    "\n",
    "#### Example: \n",
    "\n",
    "The following example, taken from [Wasserman](#WAS04) and originally given by Berger and Wolpert (1984), is interesting to understand CI in the context of a frequentist paradigm. Let $\\theta$ be a fixed known real number, and $X_1$, $X_2$ be two independent random variables such that $p(X_i = 1) = p(X_i = -1) = 1/2$. Now let's define another random variable, $Y_i = \\theta+X_i$, and suppose that you observe obly $Y_1$ and $Y_2$. We can then define the following confidence interval (that contains effectively one point):   \n",
    "\n",
    "\n",
    "$$\n",
    "C~=~{Y_1 - 1} ~{\\rm {if~}} Y_1 = Y_2   \\\\\n",
    "C~=~{(Y_1 + Y_2)/2} ~{\\rm {if~}} Y_1 \\neq Y_2\n",
    "$$\n",
    "\n",
    "\n",
    "You can check, no matter what $\\theta$ is, you have $p(\\theta) \\in C = 3/4$, which means that we have 75% confidence interval. \n",
    "Let's imagine that we do an experiment and draw $Y_1 = 18$ and $Y_2=16$. Then our 75% confidence interval is {17}. However, you are certain that $\\theta$ = 17. This does not mean that CI in the context of classical inference is nonsense, it simply underlines that you cannot make a probability statement about $\\theta$ based on your CI. The only valid probability statement about $\\theta$ you can make is $p(\\theta ~\\in ~C| Y_1, Y_2 ) = 1$.  \n",
    "\n",
    "If you want to interpret a confidence interval as a statement about the probability that $\\theta$ is in a given range, then you'll have to wait for our class on Bayesian inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3 Hypothesis testing:\n",
    "\n",
    "The concept is as it sounds: We start with some theory/model, that we call a **null hypothesis**, and we ask if the data provide sufficient evidence to reject the theory/model. If not, then we retain the model. \n",
    "\n",
    "** Example: **\n",
    "Let's assume that we have an ensemble $X_1, ..., X_n$ of outcomes of independent dice rolls. We can test the hypothesis that the dice is fair. We will denote $H_0$ the hypothesis that the dice is fair, and $H_1$ the alternative hypothesis. Statistically we would write $H_0: p=1/6$ and $H_1: p \\neq 1/6 $. Our inference will consist in getting an estimator $\\hat{p}$ of $p$, and see by how much $\\hat{p}$ differ from 1/6. Hypothesis testing will consists in having/finding objective criteria to accept/retain a null hypothesis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Maximum Likelihood <a class=\"anchor\" id=\"III\"></a>\n",
    "\n",
    "A common way, in the frequentist sense, to make a point estimation and derive a confidence interval, it through Maximum Likelihood analysis. \n",
    "\n",
    "The first thing to do in that approach is to choose a model $M(\\theta)$ that is supposed to describe the underlying population from which are drawn the data. This allows then to calculate a likelihood as explained below. \n",
    "\n",
    "### III.1 Likelihood:\n",
    "\n",
    "The Likelihood $L$ of a model and of its parameters is defined as \n",
    "$L~=~p(D \\,|\\,M(\\bf{\\theta}))$. Hence, this is the probability of Data given a model (in fact, given a model and its associated set of parameters). \n",
    "When we talk about the likelihoods of different models we are in general talking about the \n",
    "likelihoods of different sets of parameter values. \n",
    "\n",
    "It is important to note that a likelihood is not strictly speaking a probability as the sum of all the possible outcomes of a model must sum up to one, while the sum of the likelihood of the models (param) needed to explain the data do not have to add up to 1. This can be illustrated using a Gaussian case.   \n",
    "\n",
    "Let's imagine that we have an ensemble of $N$ *independent* random variable {$x_i$} drawn from a normal (i.e. gaussian) distribution of mean $\\mu$ and width $\\sigma$ (i.e. errors on all the measurements $x_i$ are the same (\"homoscedastic\"). \n",
    "\n",
    "We know that the probability of a given measurement $x_k$ is:\n",
    "\n",
    "$$\n",
    "p(x | \\mu, \\sigma ) = \\frac{1}{\\sigma \\sqrt{2\\,\\pi}} \\, \\exp\\left[-0.5 \\left (\\frac{x - \\mu}{\\sigma} \\right)^2\\right] \n",
    "$$\n",
    "\n",
    "If each measurement is independent of the other, we can calculate the likelihood as:\n",
    "\n",
    "$$\n",
    "L \\equiv p({x_i} | \\mu, \\sigma ) = \\prod_{i=1}^{N} \\frac{1}{\\sigma \\sqrt{2\\,\\pi}} \\, \\exp\\left[-0.5 \\left (\\frac{x_i - \\mu}{\\sigma} \\right)^2\\right]\n",
    "$$\n",
    "\n",
    "If you measure the likelihood of a data point/measurement $x$, $L$ can be considered as a function of the data. Conversely, you may also consider that you can vary model parameters to maximize the likelihood. In that case we can say that it is a function of the model. \n",
    "\n",
    "Because the likelihood can quickly become very small, one generally calculates its logarithm.  The maximum of $\\ln{L}$ (varying the parameters $\\theta$) is obtained by searching the parameters $\\theta$ that yield:\n",
    "\n",
    "$$\n",
    "\\left. \\frac{{\\rm d}ln(L(\\theta_i))}{\\rm{d}\\theta_i}\\right\\vert_{\\hat {\\theta_i}} \\equiv 0\n",
    "$$\n",
    "\n",
    "For our gaussian example, and specialised to the mean $\\mu$, we have:\n",
    "\n",
    "$$\n",
    "\\ln(L(\\mu)) = constant - \\sum_{i=1}^N \\frac{(x_i \\,- \\, \\mu)^2}{2\\,\\sigma^2}, \n",
    "$$\n",
    "\n",
    "which is maximum for:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{N} \\, \\sum_{i=1}^{N} x_i\n",
    "$$\n",
    "\n",
    "### III.2  Maximum Likelihood Estimation (MLE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Maybe add a figure like Fig. 3.6 showing several distribution h(x) with different skweness, kurtosis, ...  ?? / moments of a distributions: what are moments of order 2, 3, 4 ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of hypothesis testing:  Is a coin fair ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://people.duke.edu/~ccc14/sta-663/ComputationalStatisticsMotivation.html\n",
    "\n",
    "# Simulating data\n",
    "n = 100\n",
    "pcoin = 0.62 # actual value of p for coin\n",
    "results = scipy.stats.bernoulli(pcoin).rvs(n)\n",
    "h = sum(results)\n",
    "print h\n",
    "\n",
    "# Expected distribution for fair coin\n",
    "p = 0.5\n",
    "rv = scipy.stats.binom(n, p)\n",
    "mu = rv.mean()\n",
    "sd = rv.std()\n",
    "mu, sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using binomial test\n",
    "\n",
    "Hypothesis testing framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.binom_test(h, n, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using z-test approximation with continuity correction\n",
    "\n",
    "Use of approximation when true solution is computatioanlly expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = (h-0.5-mu)/sd\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2*(1 - scipy.stats.norm.cdf(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using simulation to estimate null distribution\n",
    "\n",
    "Use simulaiton when we don’t have any theory (e.g. data doesen’t meet assumptions of test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nsamples = 100000\n",
    "xs = np.random.binomial(n, p, nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2*np.sum(xs >= h)/(xs.size + 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum likelihood estimate of pcoin\n",
    "\n",
    "Point estimate of parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Maximum likelihood\", np.sum(results)/float(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using bootstrap to esitmate confidence intervals for pcoin\n",
    "\n",
    "Interval etsimate of parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_samples = np.random.choice(results, (nsamples, len(results)), replace=True)\n",
    "bs_ps = np.mean(bs_samples, axis=1)\n",
    "bs_ps.sort()\n",
    "print \"Bootstrap CI: (%.4f, %.4f)\" % (bs_ps[int(0.025*nsamples)], bs_ps[int(0.975*nsamples)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. References and supplementary material: <a class=\"anchor\" id=\"X\"></a>\n",
    "\n",
    "**Chapter 1** (1.2), **Chapter 3 ** (3.1) and **Chapter 4 ** (4.1 to 4.3) of the book <a class=\"anchor\" id=\"book\"></a> *Statistics, data mining and Machine learning in astronomy* by Z. Ivezic et al. in Princeton Series in Modern Astronomy. \n",
    "\n",
    "*All of statistics: a concise course in statistical inference*, Wasserman 2004  <a class=\"anchor\" id=\"WAS04\"></a>(see also errata in http://www.stat.cmu.edu/~larry/all-of-statistics/).  \n",
    "\n",
    "* Statistics in theory and Practice*, Lupton 1993 <a class=\"anchor\" id=\"LUP93\"></a>: **Chapter 2 **\n",
    "\n",
    "[Numerical recipes](http://www2.units.it/ipl/students_area/imm2/files/Numerical_Recipes.pdf) by Press et al. Cambridge University press: **Chapter 15**, **Chapter 18.7** \n",
    "\n",
    "Other useful references to know more about the topics covered in this class: \n",
    "    \n",
    "- Difference between Bayesian and Frequentists approaches:  \n",
    "\n",
    "    - Blog posts from Jacob Vander Plas: http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/   \n",
    "    - Frequentism and Bayesianism: A Python-driven Primer by J. Vander Plas: https://arxiv.org/abs/1411.5018\n",
    "    - Blog Post of Brendon Brewer: [What is a statistical model ?](https://plausibilitytheory.wordpress.com/2015/07/10/what-is-a-statistical-model/)\n",
    "    - Berkeley lecture on Likelihood: http://ib.berkeley.edu/courses/ib200b/ib200b_2009/Lectures/Nat/Likelihood%20lecture.pdf\n",
    "    - http://www.montefiore.ulg.ac.be/~kvansteen/MATH0008-2/ac20122013/Class16Oct/Supplementary%20info_AppendixC_Bayesian_Likelihood_Frequentist.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
